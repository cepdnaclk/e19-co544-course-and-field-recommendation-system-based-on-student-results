{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read grades\n",
    "df = pd.read_excel(\"Grade_CS_Students.xlsx\", na_values=['NA'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['Year of enrolment', 'ID'], axis=1)\n",
    "\n",
    "# Read titles of targets and features\n",
    "target_dict = pd.read_excel(\"targets.xlsx\").set_index('Code')['Desc'].to_dict()\n",
    "features_dict = pd.read_excel(\"features.xlsx\").set_index('Code')['Desc'].to_dict()\n",
    "\n",
    "# Split data into target and features\n",
    "features = df.drop(target_dict.keys(), axis=1)\n",
    "targets = df[target_dict.keys()]\n",
    "\n",
    "# Encode features into grades\n",
    "def encode_grade(marks):\n",
    "    # Convert scores into grades\n",
    "    if marks > 85:\n",
    "        return 0  #'A+'\n",
    "    elif 80 <= marks <= 85:\n",
    "        return 1  #'A'\n",
    "    elif 75 <= marks < 80:\n",
    "        return 2  #'A-'\n",
    "    elif 70 <= marks < 75:\n",
    "        return 3  #'B+'\n",
    "    elif 65 <= marks < 70:\n",
    "        return 4  #'B'\n",
    "    elif 60 <= marks < 65:\n",
    "        return 5  #'B-'\n",
    "    elif 55 <= marks < 60:\n",
    "        return 6  #'C+'\n",
    "    elif 50 <= marks < 55:\n",
    "        return 7  #'C'\n",
    "    elif 45 <= marks < 50:\n",
    "        return 8  #'C-'\n",
    "    elif 40 <= marks < 45:\n",
    "        return 9 #'D+'\n",
    "    elif 35 <= marks < 40:\n",
    "        return 10 #'D'\n",
    "    elif marks < 35:\n",
    "        return 11 #'E'\n",
    "    else:\n",
    "        return pd.NA\n",
    "    \n",
    "# Encode features and features\n",
    "encoded_features = pd.DataFrame()\n",
    "for column in features.columns:\n",
    "    encoded_features[column] = features[column].apply(encode_grade)\n",
    "encoded_targets = pd.DataFrame()\n",
    "for column in targets.columns:\n",
    "    encoded_targets[column] = targets[column].apply(encode_grade)\n",
    "    \n",
    "# Compare NaN values before and after    \n",
    "nan_before = features.isna()\n",
    "nan_after = encoded_features.isna()\n",
    "if (nan_after.equals(nan_before) == False):\n",
    "    print(\"WARNING: NaN mismatch in feature encoding\")\n",
    "nan_before = targets.isna()\n",
    "nan_after = encoded_targets.isna()\n",
    "if (nan_after.equals(nan_before) == False):\n",
    "    print(\"WARNING: NaN mismatch in target encoding\")\n",
    "\n",
    "# Save encoded features and targets\n",
    "encoded_features.to_csv('encoded_features.csv', index=False)    \n",
    "encoded_targets.to_csv('encoded_targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a34c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib's interactive mode\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "encoded_features = pd.read_csv('encoded_features.csv')\n",
    "encoded_targets = pd.read_csv('encoded_targets.csv')\n",
    "\n",
    "df = pd.concat([encoded_features, encoded_targets], axis=0)\n",
    "\n",
    "# Null count\n",
    "df.isnull().sum()\n",
    "\n",
    "# Box plots\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.boxplot(data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "imputed_features = pd.DataFrame()\n",
    "imputed_targets  = pd.DataFrame()\n",
    "\n",
    "# Since the data is skewed replace with the median\n",
    "for col in encoded_features.columns:\n",
    "    imputed_features[col] = pd.to_numeric(encoded_features[col], errors='coerce')  # Convert to numeric, set non-numeric to NaN\n",
    "    imputed_features.fillna({col: encoded_features[col].median()}, inplace=True)   # Fill NaN with median of the column\n",
    "    \n",
    "for col in encoded_targets.columns:\n",
    "    imputed_targets[col] = pd.to_numeric(encoded_targets[col], errors='coerce')  # Convert to numeric, set non-numeric to NaN\n",
    "    imputed_targets.fillna({col: encoded_targets[col].median()}, inplace=True)   # Fill NaN with median of the column\n",
    "    \n",
    "print(imputed_features.isna().sum()) \n",
    "print(imputed_targets.isna().sum()) \n",
    "    \n",
    "# Save imputed features and targets\n",
    "imputed_features.to_csv('imputed_features.csv', index=False)    \n",
    "imputed_targets.to_csv('imputed_targets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "encoded_features = pd.read_csv('encoded_features.csv')\n",
    "encoded_targets = pd.read_csv('encoded_targets.csv')\n",
    "\n",
    "profile_df = pd.concat([encoded_features, encoded_targets], axis=1)\n",
    "\n",
    "# Generate the report\n",
    "profile = ProfileReport(profile_df, title='Profile Report', explorative=True)\n",
    "profile.to_file(\"profiling-report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Read dataset\n",
    "imputed_features = pd.read_csv('imputed_features.csv')    \n",
    "imputed_targets  = pd.read_csv('imputed_targets.csv')\n",
    "\n",
    "# Read titles of targets and features\n",
    "target_dict = pd.read_excel(\"targets.xlsx\").set_index('Code')['Desc'].to_dict()\n",
    "features_dict = pd.read_excel(\"features.xlsx\").set_index('Code')['Desc'].to_dict()\n",
    "\n",
    "correlations = {}\n",
    "\n",
    "for column in imputed_targets.columns:\n",
    "    correlation = imputed_features.corrwith(imputed_targets[column])\n",
    "    correlation.sort_values(inplace=True, ascending=False)\n",
    "    correlations[column] = correlation\n",
    "\n",
    "# Display correlations as a formatted table\n",
    "for target_code, correlation in correlations.items():\n",
    "    target_title = target_dict.get(target_code, \"Unknown Target\")\n",
    "    \n",
    "    data = []\n",
    "    for feature_code, corr_value in correlation.items():\n",
    "        feature_title = features_dict.get(feature_code, \"Unknown Feature\")\n",
    "        data.append([f\"{feature_title} ({feature_code})\", np.round(corr_value, decimals=2)])\n",
    "    \n",
    "    print(tabulate(data, headers=[f\"{target_title} ({target_code})\", \"\"], tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import json \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Function to merge small classes into the next larger class\n",
    "def merge_small_classes(target_column, threshold=4):\n",
    "    if isinstance(target_column, np.ndarray):\n",
    "        target_column = pd.Series(target_column)\n",
    "    value_counts = target_column.value_counts()\n",
    "    small_classes = value_counts[value_counts < threshold].index\n",
    "    for small_class in small_classes:\n",
    "        # Find the next larger class\n",
    "        larger_classes = value_counts[value_counts >= threshold].index\n",
    "        if len(larger_classes) > 0:\n",
    "            next_larger_class = larger_classes[0]\n",
    "            target_column[target_column == small_class] = next_larger_class\n",
    "        else:\n",
    "            # If no larger class exists, keep the class as is\n",
    "            continue\n",
    "    return target_column\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def train_model_and_evaluate_for_each_target(features_dict, targets_dict):\n",
    "    # Iterate over each resampled dataset\n",
    "    for column, (features, target) in features_dict.items():\n",
    "        \n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Fix class imbalances\n",
    "        y_train = merge_small_classes(y_train)\n",
    "        smote = SMOTE(k_neighbors = 3)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        #X_train_resampled, y_train_resampled = X_train, y_train\n",
    "        \n",
    "        # Labels should start from 0, 1, 2, ... for XGBoost\n",
    "        le = LabelEncoder()\n",
    "        y_train_resampled = le.fit_transform(y_train_resampled)\n",
    "        y_test = le.fit_transform(y_test)\n",
    "        \n",
    "        # Setup model and hyperparameter tuning\n",
    "        #model = RandomForestClassifier()\n",
    "        #model_name = \"rf\"\n",
    "        #gs_space = {\n",
    "        #    'max_depth': [3,5,7,10],\n",
    "        #    'n_estimators': [100, 200, 300, 400, 500],\n",
    "        #    'max_features': [10, 20, 30 , 40],\n",
    "        #    'min_samples_leaf': [1, 2, 4]\n",
    "        #}\n",
    "        \n",
    "        '''\n",
    "        classes_weights = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(train_df['class']),\n",
    "                                             train_df['class']))\n",
    "\n",
    "        weights = np.ones(y_train.shape[0], dtype = 'float')\n",
    "        for i, val in enumerate(y_train):\n",
    "            weights[i] = classes_weights[val-1]\n",
    "        '''\n",
    "        \n",
    "        model = XGBClassifier()\n",
    "        model_name = \"xg\"\n",
    "        gs_space = {\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'max_depth': [2, 3, 4],\n",
    "            'learning_rate': [0.1, 0.01, 0.001]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        #SVM\n",
    "        #model = SVC()\n",
    "        #gs_space = {\n",
    "        #    'kernel': ['rbf'],\n",
    "        #}\n",
    "        #model_name = 'svc'\n",
    "\n",
    "        #MLP\n",
    "        # model = MLPClassifier()\n",
    "        # model_name = 'MLP'\n",
    "\n",
    "        scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "        grid = GridSearchCV(model, gs_space, scoring=scoring, refit=\"roc_auc\", verbose = 2, return_train_score=True, n_jobs=-1)\n",
    "        model_grid = grid.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        best_results = {}\n",
    "        for col in model_grid.cv_results_.keys():\n",
    "            best_results[col] = model_grid.cv_results_[col][model_grid.best_index_]\n",
    "\n",
    "        best_model = model_grid.best_estimator_\n",
    "        \n",
    "        # Test Set Evaluation\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Calculate the confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        best_results['test_accuracy']     = accuracy\n",
    "        best_results['test_precision']    = precision\n",
    "        best_results['test_f1']           = f1\n",
    "        best_results['test_recall']       = recall\n",
    "        best_results['confusion_matrix']  = conf_matrix\n",
    "        \n",
    "        print(best_results)\n",
    "        \n",
    "        with open(f'{model_name}_{column}.txt', 'w') as file:\n",
    "            file.write(json.dumps(best_results, cls=NpEncoder))\n",
    "\n",
    "        \n",
    "# Read dataset\n",
    "imputed_features = pd.read_csv('imputed_features.csv').astype(int)  \n",
    "imputed_targets  = pd.read_csv('imputed_targets.csv').astype(int)\n",
    "\n",
    "features_dict = {}\n",
    "targets_dict = {}\n",
    "\n",
    "for column in imputed_targets.columns:\n",
    "    features_dict[column] = (imputed_features, imputed_targets[column])\n",
    "    targets_dict[column]  = imputed_targets[column]\n",
    "\n",
    "train_model_and_evaluate_for_each_target(features_dict, targets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e588c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41281c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
